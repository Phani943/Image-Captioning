{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
    "colab": {
        "provenance": []
    },
    "kernelspec": {
        "name": "python3",
            "display_name": "Python 3"
    },
    "language_info": {
        "name": "python"
    }
},
    "cells": [
    {
        "cell_type": "markdown",
        "source": [
            "## **Install Dependencies**\n",
            "\n",
            "- !pip install boto3 datasets\n",
            "- !pip install --upgrade pyarrow datasets"
        ],
        "metadata": {
            "id": "35v3cEdEhU9I"
        }
    },
    {
        "cell_type": "code",
        "execution_count": 1,
        "source": [
            "import os\n",
            "import boto3\n",
            "import shutil\n",
            "import zipfile\n",
            "import botocore\n",
            "import warnings\n",
            "import pandas as pd\n",
            "from tqdm import tqdm\n",
            "from concurrent import futures\n",
            "from datasets import load_dataset\n",
            "\n",
            "warnings.filterwarnings('ignore')\n",
            "\n",
            "hugging_df = pd.DataFrame(load_dataset(\"Andyrasika/image_captioning\", split=\"train\"))"
        ],
        "metadata": {
            "colab": {
                "base_uri": "https://localhost:8080/",
                "height": 81,
                "referenced_widgets": [
                    "f123868b32ff42b1b153a05bfe3912ad",
                    "cd3ac96982394c3287fa4a80d55bc2d4",
                    "c8dcd45641014683975a6ba7d4a372b8",
                    "f24daa9c37db4b958a9373f3b26d654a",
                    "2d0abc47860641e1a008e6437697497a",
                    "a3b7f31a939746c88bc5dc304489e9b7",
                    "cc55d4998db947f18c0e471d82ab6d11",
                    "d305baf5e12a4bf28ba69a9d6b184027",
                    "f18cb26fdb5445eab1e91fe5a76236bb",
                    "4b85a422f52344cfa8659b3a541fec97",
                    "007c56275ae94740a928f507bfdab78c",
                    "c744d848eff846088331ac1f42156209",
                    "4404cea976754f9a8758979193484e8e",
                    "a6e0c5d5eeb54818a08c5f04c957b7c5",
                    "3dd1103fba364088b8d8789585f732cc",
                    "58e279b5dc7640498ba9f405bbc0ad9d",
                    "fb4c6635e5cd45d08d9e59f85b3514bb",
                    "36c42fa8cea34afca8ccd4770708d3d3",
                    "d20872249e06471c80217661d22e0d14",
                    "f9907561b91e4649b6e107c225fdb456",
                    "44b0367e0a4549edaf122eee73414576",
                    "045b85d03caf42edb487b4575ccc50bf"
                ]
            },
            "id": "i84zCx6XH3Ye",
            "outputId": "b0fdc586-abbe-4204-b779-e6658265ee4e"
        },
        "outputs": [
            {
                "output_type": "display_data",
                "data": {
                    "text/plain": [
                        "Downloading data:   0%|          | 0.00/139M [00:00<?, ?B/s]"
                    ],
                    "application/vnd.jupyter.widget-view+json": {
                        "version_major": 2,
                        "version_minor": 0,
                        "model_id": "f123868b32ff42b1b153a05bfe3912ad"
                    }
                },
                "metadata": {}
            },
            {
                "output_type": "display_data",
                "data": {
                    "text/plain": [
                        "Generating train split:   0%|          | 0/507444 [00:00<?, ? examples/s]"
                    ],
                    "application/vnd.jupyter.widget-view+json": {
                        "version_major": 2,
                        "version_minor": 0,
                        "model_id": "c744d848eff846088331ac1f42156209"
                    }
                },
                "metadata": {}
            }
        ]
    },
    {
        "cell_type": "code",
        "execution_count": 2,
        "source": [
            "max_rows = 200000\n",
            "resultant_data = set()\n",
            "seen_ids = set()\n",
            "\n",
            "progress_bar = tqdm(total=max_rows, desc=\"Processing Rows\")\n",
            "\n",
            "def select_data(data_row):\n",
            "    return (data_row['image_id'], data_row['caption'])\n",
            "\n",
            "for _, data_row in hugging_df.iterrows():\n",
            "    if len(resultant_data) >= max_rows:\n",
            "        break\n",
            "    data_tuple = select_data(data_row)\n",
            "    image_id = data_tuple[0]\n",
            "    if image_id not in seen_ids:\n",
            "        seen_ids.add(image_id)\n",
            "        resultant_data.add(data_tuple)\n",
            "        progress_bar.update(1)\n",
            "\n",
            "data = pd.DataFrame(list(resultant_data), columns=['image_id', 'caption'])\n",
            "\n",
            "data.to_csv('unique_images.csv', index=False)"
        ],
        "metadata": {
            "colab": {
                "base_uri": "https://localhost:8080/"
            },
            "id": "DAfAACzJH54_",
            "outputId": "8354cfbd-6ce0-4c56-94c2-9f60ac4b9460"
        },
        "outputs": [
            {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                    "Processing Rows: 100%|█████████▉| 199933/200000 [00:14<00:00, 14859.39it/s]"
                ]
            }
        ]
    },
    {
        "cell_type": "code",
        "execution_count": 3,
        "source": [
            "BUCKET_NAME = 'open-images-dataset'\n",
            "bucket = boto3.resource(\n",
            "    's3', config=botocore.config.Config(\n",
            "        signature_version=botocore.UNSIGNED)).Bucket(BUCKET_NAME)\n",
            "\n",
            "splits = ['train', 'validation', 'test']\n",
            "download_folder = f'images_{max_rows//1000}k'\n",
            "\n",
            "if not os.path.exists(download_folder):\n",
            "    os.makedirs(download_folder)"
        ],
        "metadata": {
            "id": "EvH8A1crH9R3"
        },
        "outputs": []
    },
    {
        "cell_type": "code",
        "execution_count": 4,
        "source": [
            "from tqdm.notebook import tqdm\n",
            "\n",
            "def download_one_image(image_id):\n",
            "    for split in splits:\n",
            "        try:\n",
            "            file_path = os.path.join(download_folder, f'{image_id}.jpg')\n",
            "            bucket.download_file(f'{split}/{image_id}.jpg', file_path)\n",
            "            return 1\n",
            "        except botocore.exceptions.ClientError:\n",
            "            continue\n",
            "        except Exception as e:\n",
            "            print(f'Unexpected error: {e}')\n",
            "            return None\n",
            "    return None\n",
            "\n",
            "def process_image(row):\n",
            "    image_id = row['image_id']\n",
            "    result = download_one_image(image_id)\n",
            "    if result is None:\n",
            "        print(f'ERROR: Image `{image_id}` not found in any of the specified splits.')\n",
            "        return None\n",
            "    else:\n",
            "        caption = row['caption']\n",
            "        return {'image_id': image_id, 'caption': caption}\n",
            "\n",
            "info_list = []\n",
            "with futures.ThreadPoolExecutor(max_workers=10) as executor:\n",
            "    results = list(tqdm(executor.map(process_image, data.to_dict('records')), total=data.shape[0]))\n",
            "\n",
            "info_list = [result for result in results if result is not None]\n",
            "info_df = pd.DataFrame(info_list)\n",
            "info_df.to_csv('image_info.csv', index=False)"
        ],
        "metadata": {
            "colab": {
                "base_uri": "https://localhost:8080/",
                "height": 208,
                "referenced_widgets": [
                    "b0843ba44aee47b5ad177cb8fbdccba6",
                    "4a3d54b7a8ad4a6c89f43ce15cf09c83",
                    "e3b4af6b0f98419b8d8a49be24a76172",
                    "78f16ba097f14086a888c8ba2ded2014",
                    "86d6326c051443a883654f2d950d42ea",
                    "51928ca02b2546dd9dc036d042626729",
                    "38df60f4a97d473c990925e78b92ea5b",
                    "3a610fd0054349bb9517f35c9c895a72",
                    "d08c79de74404703b2fa650d6236e7cd",
                    "f3770c2cf5724632a018c914e555c2f2",
                    "42f859836f5c435ea74ab3a8849b5cf6"
                ]
            },
            "id": "uThOjdYyH_q9",
            "outputId": "dcdff7c7-59f2-4a63-df63-925a023054b9"
        },
        "outputs": [
            {
                "output_type": "display_data",
                "data": {
                    "text/plain": [
                        "  0%|          | 0/200000 [00:00<?, ?it/s]"
                    ],
                    "application/vnd.jupyter.widget-view+json": {
                        "version_major": 2,
                        "version_minor": 0,
                        "model_id": "b0843ba44aee47b5ad177cb8fbdccba6"
                    }
                },
                "metadata": {}
            },
            {
                "output_type": "stream",
                "name": "stderr",
                "text": [
                    "\rProcessing Rows: 100%|██████████| 200000/200000 [00:30<00:00, 14859.39it/s]WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com. Connection pool size: 10\n",
                    "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com. Connection pool size: 10\n",
                    "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com. Connection pool size: 10\n",
                    "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com. Connection pool size: 10\n",
                    "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com. Connection pool size: 10\n",
                    "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com. Connection pool size: 10\n",
                    "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com. Connection pool size: 10\n",
                    "WARNING:urllib3.connectionpool:Connection pool is full, discarding connection: open-images-dataset.s3.amazonaws.com. Connection pool size: 10\n"
                ]
            }
        ]
    },
    {
        "cell_type": "code",
        "execution_count": 5,
        "source": [
            "!pip install kaggle"
        ],
        "metadata": {
            "colab": {
                "base_uri": "https://localhost:8080/"
            },
            "id": "CrwsTcksIFk5",
            "outputId": "e5f2dc16-b23c-49dc-8291-63330ed26a78"
        },
        "outputs": [
            {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                    "Requirement already satisfied: kaggle in /usr/local/lib/python3.10/dist-packages (1.6.14)\n",
                    "Requirement already satisfied: six>=1.10 in /usr/local/lib/python3.10/dist-packages (from kaggle) (1.16.0)\n",
                    "Requirement already satisfied: certifi>=2023.7.22 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2024.7.4)\n",
                    "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.8.2)\n",
                    "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.32.3)\n",
                    "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from kaggle) (4.66.4)\n",
                    "Requirement already satisfied: python-slugify in /usr/local/lib/python3.10/dist-packages (from kaggle) (8.0.4)\n",
                    "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from kaggle) (2.0.7)\n",
                    "Requirement already satisfied: bleach in /usr/local/lib/python3.10/dist-packages (from kaggle) (6.1.0)\n",
                    "Requirement already satisfied: webencodings in /usr/local/lib/python3.10/dist-packages (from bleach->kaggle) (0.5.1)\n",
                    "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.10/dist-packages (from python-slugify->kaggle) (1.3)\n",
                    "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.3.2)\n",
                    "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->kaggle) (3.7)\n"
                ]
            }
        ]
    },
    {
        "cell_type": "code",
        "execution_count": 6,
        "source": [
            "from google.colab import files\n",
            "files.upload();"
        ],
        "metadata": {
            "colab": {
                "base_uri": "https://localhost:8080/",
                "height": 71
            },
            "id": "0-1ZSRuiItVP",
            "outputId": "84913038-196d-467f-c325-912f1d02b310"
        },
        "outputs": [
            {
                "output_type": "display_data",
                "data": {
                    "text/plain": [
                        "<IPython.core.display.HTML object>"
                    ],
                    "text/html": [
                        "\n",
                        "     <input type=\"file\" id=\"files-6e5b2c2a-7d6d-4bed-89d9-55d577d9aaaf\" name=\"files[]\" multiple disabled\n",
                        "        style=\"border:none\" />\n",
                        "     <output id=\"result-6e5b2c2a-7d6d-4bed-89d9-55d577d9aaaf\">\n",
                        "      Upload widget is only available when the cell has been executed in the\n",
                        "      current browser session. Please rerun this cell to enable.\n",
                        "      </output>\n",
                        "      <script>// Copyright 2017 Google LLC\n",
                        "//\n",
                        "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
                        "// you may not use this file except in compliance with the License.\n",
                        "// You may obtain a copy of the License at\n",
                        "//\n",
                        "//      http://www.apache.org/licenses/LICENSE-2.0\n",
                        "//\n",
                        "// Unless required by applicable law or agreed to in writing, software\n",
                        "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
                        "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
                        "// See the License for the specific language governing permissions and\n",
                        "// limitations under the License.\n",
                        "\n",
                        "/**\n",
                        " * @fileoverview Helpers for google.colab Python module.\n",
                        " */\n",
                        "(function(scope) {\n",
                        "function span(text, styleAttributes = {}) {\n",
                        "  const element = document.createElement('span');\n",
                        "  element.textContent = text;\n",
                        "  for (const key of Object.keys(styleAttributes)) {\n",
                        "    element.style[key] = styleAttributes[key];\n",
                        "  }\n",
                        "  return element;\n",
                        "}\n",
                        "\n",
                        "// Max number of bytes which will be uploaded at a time.\n",
                        "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
                        "\n",
                        "function _uploadFiles(inputId, outputId) {\n",
                        "  const steps = uploadFilesStep(inputId, outputId);\n",
                        "  const outputElement = document.getElementById(outputId);\n",
                        "  // Cache steps on the outputElement to make it available for the next call\n",
                        "  // to uploadFilesContinue from Python.\n",
                        "  outputElement.steps = steps;\n",
                        "\n",
                        "  return _uploadFilesContinue(outputId);\n",
                        "}\n",
                        "\n",
                        "// This is roughly an async generator (not supported in the browser yet),\n",
                        "// where there are multiple asynchronous steps and the Python side is going\n",
                        "// to poll for completion of each step.\n",
                        "// This uses a Promise to block the python side on completion of each step,\n",
                        "// then passes the result of the previous step as the input to the next step.\n",
                        "function _uploadFilesContinue(outputId) {\n",
                        "  const outputElement = document.getElementById(outputId);\n",
                        "  const steps = outputElement.steps;\n",
                        "\n",
                        "  const next = steps.next(outputElement.lastPromiseValue);\n",
                        "  return Promise.resolve(next.value.promise).then((value) => {\n",
                        "    // Cache the last promise value to make it available to the next\n",
                        "    // step of the generator.\n",
                        "    outputElement.lastPromiseValue = value;\n",
                        "    return next.value.response;\n",
                        "  });\n",
                        "}\n",
                        "\n",
                        "/**\n",
                        " * Generator function which is called between each async step of the upload\n",
                        " * process.\n",
                        " * @param {string} inputId Element ID of the input file picker element.\n",
                        " * @param {string} outputId Element ID of the output display.\n",
                        " * @return {!Iterable<!Object>} Iterable of next steps.\n",
                        " */\n",
                        "function* uploadFilesStep(inputId, outputId) {\n",
                        "  const inputElement = document.getElementById(inputId);\n",
                        "  inputElement.disabled = false;\n",
                        "\n",
                        "  const outputElement = document.getElementById(outputId);\n",
                        "  outputElement.innerHTML = '';\n",
                        "\n",
                        "  const pickedPromise = new Promise((resolve) => {\n",
                        "    inputElement.addEventListener('change', (e) => {\n",
                        "      resolve(e.target.files);\n",
                        "    });\n",
                        "  });\n",
                        "\n",
                        "  const cancel = document.createElement('button');\n",
                        "  inputElement.parentElement.appendChild(cancel);\n",
                        "  cancel.textContent = 'Cancel upload';\n",
                        "  const cancelPromise = new Promise((resolve) => {\n",
                        "    cancel.onclick = () => {\n",
                        "      resolve(null);\n",
                        "    };\n",
                        "  });\n",
                        "\n",
                        "  // Wait for the user to pick the files.\n",
                        "  const files = yield {\n",
                        "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
                        "    response: {\n",
                        "      action: 'starting',\n",
                        "    }\n",
                        "  };\n",
                        "\n",
                        "  cancel.remove();\n",
                        "\n",
                        "  // Disable the input element since further picks are not allowed.\n",
                        "  inputElement.disabled = true;\n",
                        "\n",
                        "  if (!files) {\n",
                        "    return {\n",
                        "      response: {\n",
                        "        action: 'complete',\n",
                        "      }\n",
                        "    };\n",
                        "  }\n",
                        "\n",
                        "  for (const file of files) {\n",
                        "    const li = document.createElement('li');\n",
                        "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
                        "    li.append(span(\n",
                        "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
                        "        `last modified: ${\n",
                        "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
                        "                                    'n/a'} - `));\n",
                        "    const percent = span('0% done');\n",
                        "    li.appendChild(percent);\n",
                        "\n",
                        "    outputElement.appendChild(li);\n",
                        "\n",
                        "    const fileDataPromise = new Promise((resolve) => {\n",
                        "      const reader = new FileReader();\n",
                        "      reader.onload = (e) => {\n",
                        "        resolve(e.target.result);\n",
                        "      };\n",
                        "      reader.readAsArrayBuffer(file);\n",
                        "    });\n",
                        "    // Wait for the data to be ready.\n",
                        "    let fileData = yield {\n",
                        "      promise: fileDataPromise,\n",
                        "      response: {\n",
                        "        action: 'continue',\n",
                        "      }\n",
                        "    };\n",
                        "\n",
                        "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
                        "    let position = 0;\n",
                        "    do {\n",
                        "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
                        "      const chunk = new Uint8Array(fileData, position, length);\n",
                        "      position += length;\n",
                        "\n",
                        "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
                        "      yield {\n",
                        "        response: {\n",
                        "          action: 'append',\n",
                        "          file: file.name,\n",
                        "          data: base64,\n",
                        "        },\n",
                        "      };\n",
                        "\n",
                        "      let percentDone = fileData.byteLength === 0 ?\n",
                        "          100 :\n",
                        "          Math.round((position / fileData.byteLength) * 100);\n",
                        "      percent.textContent = `${percentDone}% done`;\n",
                        "\n",
                        "    } while (position < fileData.byteLength);\n",
                        "  }\n",
                        "\n",
                        "  // All done.\n",
                        "  yield {\n",
                        "    response: {\n",
                        "      action: 'complete',\n",
                        "    }\n",
                        "  };\n",
                        "}\n",
                        "\n",
                        "scope.google = scope.google || {};\n",
                        "scope.google.colab = scope.google.colab || {};\n",
                        "scope.google.colab._files = {\n",
                        "  _uploadFiles,\n",
                        "  _uploadFilesContinue,\n",
                        "};\n",
                        "})(self);\n",
                        "</script> "
                    ]
                },
                "metadata": {}
            },
            {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                    "Saving kaggle.json to kaggle.json\n"
                ]
            }
        ]
    },
    {
        "cell_type": "code",
        "execution_count": 7,
        "source": [
            "!mkdir -p ~/.kaggle\n",
            "!mv kaggle.json ~/.kaggle/\n",
            "!chmod 600 ~/.kaggle/kaggle.json"
        ],
        "metadata": {
            "id": "KNUr9mRNcTAE"
        },
        "outputs": []
    },
    {
        "cell_type": "code",
        "execution_count": 8,
        "source": [
            "metadata = {\n",
            "    \"title\": \"Image Captioning Dataset 200k\",\n",
            "    \"id\": \"phanichaitanya349/captioning-dataset-200k\",\n",
            "    \"licenses\": [\n",
            "        {\n",
            "            \"name\": \"CC0-1.0\"\n",
            "        }\n",
            "    ]\n",
            "}\n",
            "\n",
            "import json\n",
            "with open('dataset-metadata.json', 'w') as f:\n",
            "    json.dump(metadata, f)"
        ],
        "metadata": {
            "id": "1xKATWNiUmjq"
        },
        "outputs": []
    },
    {
        "cell_type": "code",
        "execution_count": 9,
        "source": [
            "!mkdir img-caption-dataset\n",
            "!mv dataset-metadata.json img-caption-dataset/\n",
            "!mv image_info.csv img-caption-dataset/"
        ],
        "metadata": {
            "id": "q-IH4osOItMt"
        },
        "outputs": []
    },
    {
        "cell_type": "code",
        "execution_count": 10,
        "source": [
            "!cd images_200k"
        ],
        "metadata": {
            "id": "QoJmIGNg-7M2"
        },
        "outputs": []
    },
    {
        "cell_type": "code",
        "execution_count": 11,
        "source": [
            "def zip_and_remove(folder_path, zip_file_name):\n",
            "    with zipfile.ZipFile(zip_file_name, 'w') as zipf:\n",
            "        for root, dirs, files in os.walk(folder_path):\n",
            "            for file in tqdm(files, desc=\"Zipping and removing files\", unit=\"file\"):\n",
            "                file_path = os.path.join(root, file)\n",
            "                zipf.write(file_path, os.path.relpath(file_path, folder_path))\n",
            "                os.remove(file_path)\n",
            "\n",
            "folder_path = 'images_200k'\n",
            "zip_file_name = 'images_200k.zip'\n",
            "zip_and_remove(folder_path, zip_file_name)"
        ],
        "metadata": {
            "id": "gX4IeBxI-V_D"
        },
        "outputs": []
    },
    {
        "cell_type": "markdown",
        "source": [
            "!zip -r images_200k.zip images_200k"
        ],
        "metadata": {
            "id": "BxDORbpd_o4I"
        }
    },
    {
        "cell_type": "code",
        "execution_count": 12,
        "source": [
            "!mv images_200k.zip img-caption-dataset/"
        ],
        "metadata": {
            "id": "y1PbsnXPOZ_c"
        },
        "outputs": []
    },
    {
        "cell_type": "code",
        "execution_count": 13,
        "source": [
            "!kaggle datasets create -p img-caption-dataset/"
        ],
        "metadata": {
            "colab": {
                "base_uri": "https://localhost:8080/"
            },
            "id": "tcnM2WRGItKZ",
            "outputId": "f7a16cd5-984e-4abe-ea3c-d7db28dbc227"
        },
        "outputs": [
            {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                    "Starting upload for file image_info.csv\n",
                    "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.6.17 / client 1.6.14)\n",
                    "100% 37.2M/37.2M [00:01<00:00, 37.5MB/s]\n",
                    "Upload successful: image_info.csv (37MB)\n",
                    "Starting upload for file images_200k.zip\n",
                    "100% 58.5G/58.5G [09:09<00:00, 114MB/s]\n",
                    "Upload successful: images_200k.zip (59GB)\n",
                    "Your private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/phanichaitanya349/captioning-dataset-200k\n"
                ]
            }
        ]
    },
    {
        "cell_type": "code",
        "execution_count": 14,
        "source": [],
        "metadata": {
            "id": "uhk3eboC0wXX"
        },
        "outputs": []
    }
]
}
